{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adadelta, Adam, RMSprop\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NFWBS_PUF_2016_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(df, include_strings):\n",
    "    \"\"\"\n",
    "    Filter DataFrame columns containing any of the strings in include_strings.\n",
    "    \n",
    "    Args:\n",
    "    df (pandas.DataFrame): Input DataFrame.\n",
    "    include_strings (list): List of strings that need to be included in the column names.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    filtered_columns = []\n",
    "    for col in df.columns:\n",
    "        if any(include_string in col.lower() for include_string in include_strings):\n",
    "            filtered_columns.append(col)\n",
    "    return df[filtered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_columns(df, include_strings=['fwb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "   # convert form camel case to snake case\n",
    "   df.columns = (df.columns\n",
    "                  .str.replace('(?<=[a-z])(?=[A-Z])', '_', regex=True)\n",
    "                  .str.lower()\n",
    "               )\n",
    "   # convert \" \" to _\n",
    "   df.columns = df.columns.str.replace(' ', '_')\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_negative_values(df):\n",
    "    \"\"\"\n",
    "    Drop all values in the DataFrame that are less than 0.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with negative values dropped.\n",
    "    \"\"\"\n",
    "    df_without_null = df[df >= 0]\n",
    "    print(len(df)-len(df_without_null.dropna()))\n",
    "    return df_without_null.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "df = drop_negative_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = [col for col in df.columns if 'score' in col.lower()]\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train = train_set.drop(columns=target_column, errors='ignore')\n",
    "train_labels = train_set[target_column]\n",
    "\n",
    "test = test_set.drop(columns=target_column, errors='ignore')\n",
    "test_labels = test_set[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials, space_eval, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                       \n",
      "{'activation': 'relu', 'batch_size': 77.89439400341456, 'dropout': 0.4487145443722915, 'hiddenLayerOne': 264.7566015978515, 'hiddenLayerTwo': 948.8122591534299, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4B47C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4B47C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4B47C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4B47C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 25s   \n",
      " 11/160 [=>............................] - ETA: 0s    \n",
      " 25/160 [===>..........................] - ETA: 0s   \n",
      " 38/160 [======>.......................] - ETA: 0s   \n",
      " 53/160 [========>.....................] - ETA: 0s   \n",
      " 67/160 [===========>..................] - ETA: 0s   \n",
      " 82/160 [==============>...............] - ETA: 0s   \n",
      " 95/160 [================>.............] - ETA: 0s   \n",
      "109/160 [===================>..........] - ETA: 0s   \n",
      "123/160 [======================>.......] - ETA: 0s   \n",
      "137/160 [========================>.....] - ETA: 0s   \n",
      "151/160 [===========================>..] - ETA: 0s   \n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 35.418881955132086, 'dropout': 0.4300817391389884, 'hiddenLayerOne': 477.7779776789644, 'hiddenLayerTwo': 799.530080663266, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      "  2%|‚ñè         | 1/50 [01:03<51:38, 63.23s/trial, best loss: 10.533933205498412]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D56EC00> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D56EC00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D56EC00> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D56EC00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                              \n",
      " 46/160 [=======>......................] - ETA: 0s                             \n",
      " 81/160 [==============>...............] - ETA: 0s                             \n",
      "127/160 [======================>.......] - ETA: 0s                             \n",
      "158/160 [============================>.] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 1ms/step                         \n",
      "\n",
      "Params testing:                                                                    \n",
      "{'activation': 'relu', 'batch_size': 84.98635059232835, 'dropout': 0.657017519355836, 'hiddenLayerOne': 616.4284453746826, 'hiddenLayerTwo': 347.84480224993763, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      "  4%|‚ñç         | 2/50 [03:09<1:20:20, 100.43s/trial, best loss: 10.533933205498412]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D54E5C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D54E5C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D54E5C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D54E5C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 6s                                 \n",
      " 54/160 [=========>....................] - ETA: 0s                                \n",
      "103/160 [==================>...........] - ETA: 0s                                \n",
      "142/160 [=========================>....] - ETA: 0s                                \n",
      "160/160 [==============================] - 0s 1ms/step                            \n",
      "\n",
      "Params testing:                                                                    \n",
      "{'activation': 'relu', 'batch_size': 115.29809479184595, 'dropout': 0.6455271338315429, 'hiddenLayerOne': 272.01828635006393, 'hiddenLayerTwo': 849.4279710435081, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      "  6%|‚ñå         | 3/50 [03:31<50:43, 64.75s/trial, best loss: 10.533933205498412]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4E8400> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4E8400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4E8400> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D4E8400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 43/160 [=======>......................] - ETA: 0s                             \n",
      " 80/160 [==============>...............] - ETA: 0s                             \n",
      "116/160 [====================>.........] - ETA: 0s                             \n",
      "154/160 [===========================>..] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 1ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 117.97231410504823, 'dropout': 0.6857735161780889, 'hiddenLayerOne': 578.5058437343234, 'hiddenLayerTwo': 1015.6757111392951, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      "  8%|‚ñä         | 4/50 [03:50<35:31, 46.34s/trial, best loss: 10.533933205498412]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D505C60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D505C60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D505C60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D505C60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 12s                             \n",
      " 21/160 [==>...........................] - ETA: 0s                              \n",
      " 42/160 [======>.......................] - ETA: 0s                             \n",
      " 62/160 [==========>...................] - ETA: 0s                             \n",
      " 84/160 [==============>...............] - ETA: 0s                             \n",
      "104/160 [==================>...........] - ETA: 0s                             \n",
      "123/160 [======================>.......] - ETA: 0s                             \n",
      "147/160 [==========================>...] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 66.35674540107767, 'dropout': 0.6753617247968987, 'hiddenLayerOne': 897.747121069551, 'hiddenLayerTwo': 331.0163402007796, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 10%|‚ñà         | 5/50 [04:15<29:10, 38.89s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D414EA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D414EA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D414EA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D414EA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                             \n",
      " 38/160 [======>.......................] - ETA: 0s                            \n",
      " 80/160 [==============>...............] - ETA: 0s                            \n",
      "124/160 [======================>.......] - ETA: 0s                            \n",
      "160/160 [==============================] - 0s 1ms/step                        \n",
      "\n",
      "Params testing:                                                                \n",
      "{'activation': 'relu', 'batch_size': 121.1305164691211, 'dropout': 0.4429152669737754, 'hiddenLayerOne': 184.10047790830643, 'hiddenLayerTwo': 476.0294281402413, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 12%|‚ñà‚ñè        | 6/50 [04:40<24:59, 34.08s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C68E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C68E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C68E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C68E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                             \n",
      " 62/160 [==========>...................] - ETA: 0s                            \n",
      "106/160 [==================>...........] - ETA: 0s                            \n",
      "151/160 [===========================>..] - ETA: 0s                            \n",
      "160/160 [==============================] - 0s 1ms/step                        \n",
      "\n",
      "Params testing:                                                                \n",
      "{'activation': 'relu', 'batch_size': 101.30016489655397, 'dropout': 0.5709976087355026, 'hiddenLayerOne': 747.6253489208524, 'hiddenLayerTwo': 79.82581338846964, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 14%|‚ñà‚ñç        | 7/50 [04:54<19:42, 27.50s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A71A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A71A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A71A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A71A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                             \n",
      " 46/160 [=======>......................] - ETA: 0s                            \n",
      " 89/160 [===============>..............] - ETA: 0s                            \n",
      "131/160 [=======================>......] - ETA: 0s                            \n",
      "160/160 [==============================] - 0s 1ms/step                        \n",
      "\n",
      "Params testing:                                                                \n",
      "{'activation': 'relu', 'batch_size': 57.51290269517246, 'dropout': 0.3640117949288041, 'hiddenLayerOne': 361.5644215133211, 'hiddenLayerTwo': 369.16898565720146, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 16%|‚ñà‚ñå        | 8/50 [05:08<16:20, 23.36s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                             \n",
      " 25/160 [===>..........................] - ETA: 0s                            \n",
      " 58/160 [=========>....................] - ETA: 0s                            \n",
      "114/160 [====================>.........] - ETA: 0s                            \n",
      "160/160 [==============================] - 0s 1ms/step                        \n",
      "\n",
      "Params testing:                                                                \n",
      "{'activation': 'relu', 'batch_size': 38.038995195789404, 'dropout': 0.37038581451965624, 'hiddenLayerOne': 444.2712087761443, 'hiddenLayerTwo': 642.8894779623654, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 18%|‚ñà‚ñä        | 9/50 [05:28<15:05, 22.08s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A5EE0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A5EE0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A5EE0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A5EE0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                             \n",
      " 36/160 [=====>........................] - ETA: 0s                            \n",
      " 67/160 [===========>..................] - ETA: 0s                            \n",
      " 97/160 [=================>............] - ETA: 0s                            \n",
      "130/160 [=======================>......] - ETA: 0s                            \n",
      "160/160 [==============================] - 0s 2ms/step                        \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 69.40017281446794, 'dropout': 0.7454621949661238, 'hiddenLayerOne': 838.0675212208439, 'hiddenLayerTwo': 779.573677672829, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 20%|‚ñà‚ñà        | 10/50 [06:01<17:02, 25.56s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7736A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7736A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7736A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7736A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                             \n",
      " 33/160 [=====>........................] - ETA: 0s                              \n",
      " 68/160 [===========>..................] - ETA: 0s                             \n",
      " 97/160 [=================>............] - ETA: 0s                             \n",
      "133/160 [=======================>......] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 1ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 39.002070575208975, 'dropout': 0.544285983585721, 'hiddenLayerOne': 341.28009942961774, 'hiddenLayerTwo': 925.0026173592537, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [06:40<19:13, 29.59s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3AA840> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3AA840>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3AA840> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3AA840>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                             \n",
      " 32/160 [=====>........................] - ETA: 0s                              \n",
      " 72/160 [============>.................] - ETA: 0s                             \n",
      "121/160 [=====================>........] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 1ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 56.66993522133076, 'dropout': 0.5739548841181148, 'hiddenLayerOne': 999.7738405878409, 'hiddenLayerTwo': 428.4525018007608, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [07:16<19:59, 31.57s/trial, best loss: 3.252260984036085]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3356C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3356C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3356C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3356C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 11s                             \n",
      " 32/160 [=====>........................] - ETA: 0s                              \n",
      " 55/160 [=========>....................] - ETA: 0s                             \n",
      " 80/160 [==============>...............] - ETA: 0s                             \n",
      "107/160 [===================>..........] - ETA: 0s                             \n",
      "134/160 [========================>.....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 41.93208357718482, 'dropout': 0.7309624925426785, 'hiddenLayerOne': 243.3640929223025, 'hiddenLayerTwo': 249.72448948539994, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [07:53<20:26, 33.15s/trial, best loss: 2.6654798819343792]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E439EE0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E439EE0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E439EE0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E439EE0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                               \n",
      " 47/160 [=======>......................] - ETA: 0s                              \n",
      " 71/160 [============>.................] - ETA: 0s                              \n",
      " 96/160 [=================>............] - ETA: 0s                              \n",
      "139/160 [=========================>....] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 1ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 100.93035530061265, 'dropout': 0.5840040218544397, 'hiddenLayerOne': 375.30889437137535, 'hiddenLayerTwo': 848.9566029357661, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [08:22<19:16, 32.13s/trial, best loss: 2.6654798819343792]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A160> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A160>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A160> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A160>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 13s                              \n",
      " 24/160 [===>..........................] - ETA: 0s                               \n",
      " 48/160 [========>.....................] - ETA: 0s                              \n",
      " 75/160 [=============>................] - ETA: 0s                              \n",
      "108/160 [===================>..........] - ETA: 0s                              \n",
      "140/160 [=========================>....] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 2ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 51.696213256758156, 'dropout': 0.5367043772898146, 'hiddenLayerOne': 73.56920574131917, 'hiddenLayerTwo': 778.5966355906629, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [08:51<18:08, 31.11s/trial, best loss: 2.6654798819343792]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4407C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4407C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4407C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4407C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 13s                              \n",
      " 37/160 [=====>........................] - ETA: 0s                               \n",
      " 79/160 [=============>................] - ETA: 0s                              \n",
      "124/160 [======================>.......] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 1ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 127.32682029596394, 'dropout': 0.5623269556311803, 'hiddenLayerOne': 564.4698271465929, 'hiddenLayerTwo': 954.1760985247975, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [09:16<16:35, 29.28s/trial, best loss: 2.6654798819343792]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568EE5C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568EE5C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568EE5C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568EE5C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 13s                              \n",
      " 21/160 [==>...........................] - ETA: 0s                               \n",
      " 51/160 [========>.....................] - ETA: 0s                              \n",
      " 86/160 [===============>..............] - ETA: 0s                              \n",
      "131/160 [=======================>......] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 1ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 63.85207968713596, 'dropout': 0.38758891846935933, 'hiddenLayerOne': 463.45721590226367, 'hiddenLayerTwo': 879.0309568246414, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [09:42<15:32, 28.27s/trial, best loss: 2.6654798819343792]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4B80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4B80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4B80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4B80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                               \n",
      " 23/160 [===>..........................] - ETA: 0s                              \n",
      " 53/160 [========>.....................] - ETA: 0s                              \n",
      " 93/160 [================>.............] - ETA: 0s                              \n",
      "126/160 [======================>.......] - ETA: 0s                              \n",
      "147/160 [==========================>...] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 2ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 106.83786550874798, 'dropout': 0.5634488892927345, 'hiddenLayerOne': 352.7315992618453, 'hiddenLayerTwo': 216.69021345923588, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [10:21<16:41, 31.29s/trial, best loss: 2.4967043159949367]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF6480> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF6480>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF6480> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF6480>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                              \n",
      " 45/160 [=======>......................] - ETA: 0s                               \n",
      " 93/160 [================>.............] - ETA: 0s                              \n",
      "136/160 [========================>.....] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 1ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 58.46446391044127, 'dropout': 0.68922577731363, 'hiddenLayerOne': 362.1647094432392, 'hiddenLayerTwo': 334.8241750805872, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [10:34<13:28, 26.08s/trial, best loss: 2.4967043159949367]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C2CA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C2CA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C2CA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C2CA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 15s                              \n",
      " 31/160 [====>.........................] - ETA: 0s                               \n",
      " 72/160 [============>.................] - ETA: 0s                              \n",
      "102/160 [==================>...........] - ETA: 0s                              \n",
      "144/160 [==========================>...] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 1ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 88.44232752421972, 'dropout': 0.2651900418712655, 'hiddenLayerOne': 1020.6369601431188, 'hiddenLayerTwo': 553.4773425182802, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [10:53<11:53, 23.78s/trial, best loss: 2.4967043159949367]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FD580> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FD580>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FD580> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FD580>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                              \n",
      " 32/160 [=====>........................] - ETA: 0s                               \n",
      " 50/160 [========>.....................] - ETA: 0s                              \n",
      " 77/160 [=============>................] - ETA: 0s                              \n",
      " 99/160 [=================>............] - ETA: 0s                              \n",
      "130/160 [=======================>......] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 2ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 85.46935453993066, 'dropout': 0.2519342338805011, 'hiddenLayerOne': 692.7787675981223, 'hiddenLayerTwo': 635.0823775648038, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [11:27<12:57, 26.80s/trial, best loss: 2.378817398235187]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FF6A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FF6A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FF6A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FF6A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 32/160 [=====>........................] - ETA: 0s                             \n",
      " 64/160 [===========>..................] - ETA: 0s                             \n",
      " 97/160 [=================>............] - ETA: 0s                             \n",
      "129/160 [=======================>......] - ETA: 0s                             \n",
      "149/160 [==========================>...] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 86.8232160562668, 'dropout': 0.26690351783973876, 'hiddenLayerOne': 682.3816967474795, 'hiddenLayerTwo': 632.2395790129711, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [11:57<13:01, 27.93s/trial, best loss: 2.247898667651472]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8605305E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8605305E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8605305E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8605305E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 11s                             \n",
      " 21/160 [==>...........................] - ETA: 0s                              \n",
      " 48/160 [========>.....................] - ETA: 0s                             \n",
      " 77/160 [=============>................] - ETA: 0s                             \n",
      "106/160 [==================>...........] - ETA: 0s                             \n",
      "131/160 [=======================>......] - ETA: 0s                             \n",
      "145/160 [==========================>...] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 91.12244037489329, 'dropout': 0.251536594452083, 'hiddenLayerOne': 996.8557661626644, 'hiddenLayerTwo': 578.7426953581544, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [12:30<13:11, 29.33s/trial, best loss: 2.247898667651472]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7722A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7722A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7722A0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83A7722A0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 17/160 [==>...........................] - ETA: 0s                             \n",
      " 34/160 [=====>........................] - ETA: 0s                             \n",
      " 58/160 [=========>....................] - ETA: 0s                             \n",
      " 81/160 [==============>...............] - ETA: 0s                             \n",
      "109/160 [===================>..........] - ETA: 0s                             \n",
      "140/160 [=========================>....] - ETA: 0s                             \n",
      "159/160 [============================>.] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 76.03857694996587, 'dropout': 0.2983473813792735, 'hiddenLayerOne': 904.66835678641, 'hiddenLayerTwo': 676.9371604519137, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [13:06<13:38, 31.47s/trial, best loss: 2.247898667651472]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D7751C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D7751C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D7751C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D7751C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 26/160 [===>..........................] - ETA: 0s                             \n",
      " 49/160 [========>.....................] - ETA: 0s                             \n",
      " 73/160 [============>.................] - ETA: 0s                             \n",
      " 96/160 [=================>............] - ETA: 0s                             \n",
      "120/160 [=====================>........] - ETA: 0s                             \n",
      "145/160 [==========================>...] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 94.35859333868757, 'dropout': 0.3139458037685006, 'hiddenLayerOne': 782.0839785246619, 'hiddenLayerTwo': 500.88142737977785, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [13:54<15:05, 36.20s/trial, best loss: 2.247898667651472]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D630B80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D630B80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D630B80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D630B80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 30/160 [====>.........................] - ETA: 0s                             \n",
      " 55/160 [=========>....................] - ETA: 0s                             \n",
      " 84/160 [==============>...............] - ETA: 0s                             \n",
      "120/160 [=====================>........] - ETA: 0s                             \n",
      "156/160 [============================>.] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 95.04090347005152, 'dropout': 0.3204963379177752, 'hiddenLayerOne': 771.6008378681755, 'hiddenLayerTwo': 485.75157866570987, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [14:28<14:14, 35.60s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D61F880> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D61F880>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D61F880> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D61F880>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 22/160 [===>..........................] - ETA: 0s                             \n",
      " 52/160 [========>.....................] - ETA: 0s                             \n",
      " 85/160 [==============>...............] - ETA: 0s                             \n",
      "107/160 [===================>..........] - ETA: 0s                             \n",
      "132/160 [=======================>......] - ETA: 0s                             \n",
      "160/160 [==============================] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                    \n",
      "{'activation': 'relu', 'batch_size': 110.29293400915282, 'dropout': 0.3099676750625944, 'hiddenLayerOne': 674.8857225896303, 'hiddenLayerTwo': 725.8512961194971, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [27:37<1:40:19, 261.70s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D735800> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D735800>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D735800> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D735800>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                                 \n",
      " 38/160 [======>.......................] - ETA: 0s                                \n",
      " 67/160 [===========>..................] - ETA: 0s                                \n",
      " 85/160 [==============>...............] - ETA: 0s                                \n",
      "102/160 [==================>...........] - ETA: 0s                                \n",
      "139/160 [=========================>....] - ETA: 0s                                \n",
      "160/160 [==============================] - 0s 2ms/step                            \n",
      "\n",
      "Params testing:                                                                    \n",
      "{'activation': 'relu', 'batch_size': 77.84552207880881, 'dropout': 0.47658583093811024, 'hiddenLayerOne': 792.3451325869217, 'hiddenLayerTwo': 133.2043685814096, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [28:08<1:10:32, 192.41s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D669080> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D669080>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D669080> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D669080>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 6s                                 \n",
      " 30/160 [====>.........................] - ETA: 0s                                \n",
      " 74/160 [============>.................] - ETA: 0s                                \n",
      "116/160 [====================>.........] - ETA: 0s                                \n",
      "140/160 [=========================>....] - ETA: 0s                                \n",
      "160/160 [==============================] - 0s 1ms/step                            \n",
      "\n",
      "Params testing:                                                                    \n",
      "{'activation': 'relu', 'batch_size': 72.72034432468467, 'dropout': 0.337104504727773, 'hiddenLayerOne': 692.3935760959768, 'hiddenLayerTwo': 494.23522241226533, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [28:31<49:34, 141.65s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D67CE00> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D67CE00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D67CE00> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D67CE00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 11s                              \n",
      " 32/160 [=====>........................] - ETA: 0s                               \n",
      " 65/160 [===========>..................] - ETA: 0s                              \n",
      " 93/160 [================>.............] - ETA: 0s                              \n",
      "137/160 [========================>.....] - ETA: 0s                              \n",
      "158/160 [============================>.] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 2ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 82.00868834062933, 'dropout': 0.40842666479796164, 'hiddenLayerOne': 867.0042275283421, 'hiddenLayerTwo': 594.7542050628683, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [28:58<35:44, 107.21s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D5E68E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D5E68E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D5E68E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D5E68E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                               \n",
      " 23/160 [===>..........................] - ETA: 0s                              \n",
      " 51/160 [========>.....................] - ETA: 0s                              \n",
      " 77/160 [=============>................] - ETA: 0s                              \n",
      "110/160 [===================>..........] - ETA: 0s                              \n",
      "132/160 [=======================>......] - ETA: 0s                              \n",
      "150/160 [===========================>..] - ETA: 0s                              \n",
      "160/160 [==============================] - 0s 2ms/step                          \n",
      "\n",
      "Params testing:                                                                  \n",
      "{'activation': 'relu', 'batch_size': 94.49324390635088, 'dropout': 0.5037447896566096, 'hiddenLayerOne': 945.2242350185957, 'hiddenLayerTwo': 705.0387065008232, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [29:28<26:39, 84.17s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DC39940> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DC39940>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DC39940> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DC39940>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 32/160 [=====>........................] - ETA: 0s                             \n",
      " 62/160 [==========>...................] - ETA: 0s                             \n",
      " 83/160 [==============>...............] - ETA: 0s                             \n",
      "102/160 [==================>...........] - ETA: 0s                             \n",
      "139/160 [=========================>....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 127.88306418049129, 'dropout': 0.28184843075283506, 'hiddenLayerOne': 625.554054588992, 'hiddenLayerTwo': 394.51514943811475, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [30:07<21:08, 70.48s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DEAC0E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DEAC0E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DEAC0E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DEAC0E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 44/160 [=======>......................] - ETA: 0s                             \n",
      " 71/160 [============>.................] - ETA: 0s                             \n",
      " 91/160 [================>.............] - ETA: 0s                             \n",
      "128/160 [=======================>......] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 101.1977372423887, 'dropout': 0.4726479212824027, 'hiddenLayerOne': 508.8671660605997, 'hiddenLayerTwo': 536.5934030770565, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [30:27<15:42, 55.41s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E2F0680> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E2F0680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E2F0680> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E2F0680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                              \n",
      " 38/160 [======>.......................] - ETA: 0s                             \n",
      " 70/160 [============>.................] - ETA: 0s                             \n",
      " 92/160 [================>.............] - ETA: 0s                             \n",
      "130/160 [=======================>......] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 81.41796008002588, 'dropout': 0.3440013454549954, 'hiddenLayerOne': 815.7865410299637, 'hiddenLayerTwo': 273.3816908559892, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [30:49<12:06, 45.38s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B860531B20> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B860531B20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B860531B20> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B860531B20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 21/160 [==>...........................] - ETA: 0s                             \n",
      " 45/160 [=======>......................] - ETA: 0s                             \n",
      " 72/160 [============>.................] - ETA: 0s                             \n",
      "106/160 [==================>...........] - ETA: 0s                             \n",
      "142/160 [=========================>....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 109.95818794466888, 'dropout': 0.42306931307835904, 'hiddenLayerOne': 743.247809722599, 'hiddenLayerTwo': 446.4261579165668, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [31:14<09:49, 39.29s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FEFC0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FEFC0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FEFC0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85E2FEFC0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 13/160 [=>............................] - ETA: 0s                             \n",
      " 40/160 [======>.......................] - ETA: 0s                             \n",
      " 74/160 [============>.................] - ETA: 0s                             \n",
      "108/160 [===================>..........] - ETA: 0s                             \n",
      "142/160 [=========================>....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 120.68405723597911, 'dropout': 0.39374219012805445, 'hiddenLayerOne': 648.1950299733516, 'hiddenLayerTwo': 616.9911729674421, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [31:40<08:12, 35.20s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C3380> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C3380>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C3380> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85D0C3380>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                             \n",
      " 40/160 [======>.......................] - ETA: 0s                              \n",
      " 72/160 [============>.................] - ETA: 0s                             \n",
      "106/160 [==================>...........] - ETA: 0s                             \n",
      "139/160 [=========================>....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 97.54368791395508, 'dropout': 0.286912099178318, 'hiddenLayerOne': 588.4856447477688, 'hiddenLayerTwo': 998.355949354813, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [32:08<07:10, 33.15s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4720> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4720>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4720> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF4720>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 32/160 [=====>........................] - ETA: 0s                             \n",
      " 53/160 [========>.....................] - ETA: 0s                             \n",
      " 75/160 [=============>................] - ETA: 0s                             \n",
      "111/160 [===================>..........] - ETA: 0s                             \n",
      "140/160 [=========================>....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 46.48338778277589, 'dropout': 0.2532463042734138, 'hiddenLayerOne': 532.5798435011438, 'hiddenLayerTwo': 195.233643818825, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [32:46<06:54, 34.55s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF7F60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF7F60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF7F60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B85BCF7F60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                              \n",
      " 33/160 [=====>........................] - ETA: 0s                             \n",
      " 69/160 [===========>..................] - ETA: 0s                             \n",
      "106/160 [==================>...........] - ETA: 0s                             \n",
      "158/160 [============================>.] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 1ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 30.703346844873415, 'dropout': 0.35299125997596603, 'hiddenLayerOne': 881.1167336386264, 'hiddenLayerTwo': 744.1590243795163, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [33:17<06:10, 33.66s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568ECEA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568ECEA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568ECEA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8568ECEA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                             \n",
      " 31/160 [====>.........................] - ETA: 0s                              \n",
      " 74/160 [============>.................] - ETA: 0s                             \n",
      "109/160 [===================>..........] - ETA: 0s                             \n",
      "134/160 [========================>.....] - ETA: 0s                             \n",
      "150/160 [===========================>..] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 114.34770146780258, 'dropout': 0.6309574366181697, 'hiddenLayerOne': 932.0262395336327, 'hiddenLayerTwo': 526.9245885810952, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [34:23<07:12, 43.21s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4439C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4439C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4439C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E4439C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 23/160 [===>..........................] - ETA: 0s                             \n",
      " 45/160 [=======>......................] - ETA: 0s                             \n",
      " 70/160 [============>.................] - ETA: 0s                             \n",
      " 94/160 [================>.............] - ETA: 0s                             \n",
      "122/160 [=====================>........] - ETA: 0s                             \n",
      "157/160 [============================>.] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 72.20844619151623, 'dropout': 0.3247219302901829, 'hiddenLayerOne': 738.3883000670113, 'hiddenLayerTwo': 668.0493003298413, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [34:53<05:52, 39.19s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A340> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A340>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A340> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E43A340>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 31/160 [====>.........................] - ETA: 0s                             \n",
      " 59/160 [==========>...................] - ETA: 0s                             \n",
      " 86/160 [===============>..............] - ETA: 0s                             \n",
      "102/160 [==================>...........] - ETA: 0s                             \n",
      "126/160 [======================>.......] - ETA: 0s                             \n",
      "150/160 [===========================>..] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 65.44707767839273, 'dropout': 0.4626199370879964, 'hiddenLayerOne': 406.78176433509554, 'hiddenLayerTwo': 294.8201146942522, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [35:28<05:03, 37.88s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DBD7100> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DBD7100>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DBD7100> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83DBD7100>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 32/160 [=====>........................] - ETA: 0s                             \n",
      " 63/160 [==========>...................] - ETA: 0s                             \n",
      " 93/160 [================>.............] - ETA: 0s                             \n",
      "129/160 [=======================>......] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 105.97957776555337, 'dropout': 0.37427930926269143, 'hiddenLayerOne': 716.4154140014163, 'hiddenLayerTwo': 825.9707615314841, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [35:48<03:49, 32.73s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E334FE0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E334FE0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E334FE0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E334FE0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                             \n",
      " 27/160 [====>.........................] - ETA: 0s                              \n",
      " 53/160 [========>.....................] - ETA: 0s                             \n",
      " 77/160 [=============>................] - ETA: 0s                             \n",
      " 97/160 [=================>............] - ETA: 0s                             \n",
      "121/160 [=====================>........] - ETA: 0s                             \n",
      "150/160 [===========================>..] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 83.29103369543513, 'dropout': 0.5053171663566441, 'hiddenLayerOne': 843.8142296948438, 'hiddenLayerTwo': 407.63135543066653, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [36:27<03:26, 34.45s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3A9C60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3A9C60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3A9C60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83E3A9C60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 41/160 [======>.......................] - ETA: 0s                             \n",
      " 78/160 [=============>................] - ETA: 0s                             \n",
      "114/160 [====================>.........] - ETA: 0s                             \n",
      "151/160 [===========================>..] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 1ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 90.05382459949124, 'dropout': 0.6040290243785209, 'hiddenLayerOne': 965.5819946562281, 'hiddenLayerTwo': 463.59080498139826, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [36:53<02:39, 31.96s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8366EBC40> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8366EBC40>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B8366EBC40> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B8366EBC40>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 10s                             \n",
      " 33/160 [=====>........................] - ETA: 0s                              \n",
      " 55/160 [=========>....................] - ETA: 0s                             \n",
      " 78/160 [=============>................] - ETA: 0s                             \n",
      "100/160 [=================>............] - ETA: 0s                             \n",
      "137/160 [========================>.....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 122.87294877233319, 'dropout': 0.4397926376467197, 'hiddenLayerOne': 69.42392527842145, 'hiddenLayerTwo': 84.18832422032528, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [37:23<02:05, 31.29s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3A65C0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 8s                              \n",
      " 49/160 [========>.....................] - ETA: 0s                             \n",
      "104/160 [==================>...........] - ETA: 0s                             \n",
      "148/160 [==========================>...] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 993us/step                       \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 62.67182593336331, 'dropout': 0.41852918190693844, 'hiddenLayerOne': 579.5964468263315, 'hiddenLayerTwo': 902.3119033701889, 'nb_epochs': 100, 'optimizer': 'adam'}\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [37:31<01:12, 24.32s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C7D80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C7D80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C7D80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C7D80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 24/160 [===>..........................] - ETA: 0s                             \n",
      " 54/160 [=========>....................] - ETA: 0s                             \n",
      " 75/160 [=============>................] - ETA: 0s                             \n",
      "100/160 [=================>............] - ETA: 0s                             \n",
      "129/160 [=======================>......] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 69.03505152091559, 'dropout': 0.7097431891911539, 'hiddenLayerOne': 284.8547503659664, 'hiddenLayerTwo': 369.22773490081056, 'nb_epochs': 100, 'optimizer': 'rmsprop'}\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [38:09<00:57, 28.56s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C5F80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C5F80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C5F80> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D3C5F80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 7s                              \n",
      " 45/160 [=======>......................] - ETA: 0s                             \n",
      " 84/160 [==============>...............] - ETA: 0s                             \n",
      "125/160 [======================>.......] - ETA: 0s                             \n",
      "159/160 [============================>.] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 1ms/step                         \n",
      "\n",
      "Params testing:                                                                 \n",
      "{'activation': 'relu', 'batch_size': 115.81329849397594, 'dropout': 0.5328308169620403, 'hiddenLayerOne': 505.4123353568331, 'hiddenLayerTwo': 768.9550263571113, 'nb_epochs': 100, 'optimizer': 'adadelta'}\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [38:28<00:25, 25.67s/trial, best loss: 2.190661873739636]WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D416700> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D416700>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D416700> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001B83D416700>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/160 [..............................] - ETA: 9s                              \n",
      " 31/160 [====>.........................] - ETA: 0s                             \n",
      " 60/160 [==========>...................] - ETA: 0s                             \n",
      " 83/160 [==============>...............] - ETA: 0s                             \n",
      "115/160 [====================>.........] - ETA: 0s                             \n",
      "141/160 [=========================>....] - ETA: 0s                             \n",
      "160/160 [==============================] - 0s 2ms/step                         \n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [38:57<00:00, 46.74s/trial, best loss: 2.190661873739636]\n",
      "Best parameters: {'batch_size': 94.35859333868757, 'dropout': 0.3139458037685006, 'hiddenLayerOne': 782.0839785246619, 'hiddenLayerTwo': 500.88142737977785, 'optimizer': 1}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'hiddenLayerOne': hp.uniform('hiddenLayerOne', 64, 1024),\n",
    "    'hiddenLayerTwo': hp.uniform('hiddenLayerTwo', 64, 1024),\n",
    "    'dropout': hp.uniform('dropout', 0.25, 0.75),\n",
    "    'batch_size': hp.uniform('batch_size', 28, 128),\n",
    "    'nb_epochs': 100,\n",
    "    'optimizer': hp.choice('optimizer', ['adadelta', 'adam', 'rmsprop']),\n",
    "    'activation': 'relu'\n",
    "}\n",
    "\n",
    "def f_nn(params):\n",
    "    print('Params testing: ', params)\n",
    "    model = Sequential([\n",
    "        Dense(int(params['hiddenLayerOne']), activation=params['activation'], input_shape=(train.shape[1],)),  # Input layer\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(int(params['hiddenLayerTwo']), activation=params['activation']),  # Hidden layer\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(1, activation='linear')  # Output layer for numerical prediction\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=params['optimizer'])\n",
    "\n",
    "    model.fit(train, train_labels, epochs=params['nb_epochs'], batch_size=int(params['batch_size']), verbose=0)\n",
    "\n",
    "    y_pred = model.predict(train)\n",
    "    mse_train = mean_squared_error(train_labels, y_pred)\n",
    "\n",
    "    return {'loss': mse_train, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "print('Best parameters:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters: {'batch_size': 94.35859333868757, 'dropout': 0.3139458037685006, 'hiddenLayerOne': 782.0839785246619, 'hiddenLayerTwo': 500.88142737977785, 'optimizer': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FWB1_1', 'FWB1_2', 'FWB1_3', 'FWB1_4', 'FWB1_5', 'FWB1_6', 'FWB2_1',\n",
      "       'FWB2_2', 'FWB2_3', 'FWB2_4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
